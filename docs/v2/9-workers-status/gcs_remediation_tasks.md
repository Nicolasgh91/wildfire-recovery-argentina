# ðŸ› ï¸ Plan de Tareas TÃ©cnicas: RemediaciÃ³n GCS Workers

**Referencia:** `gcs_connectivity_diagnostic.md`  
**Fecha:** 2026-02-09  
**Prioridad Global:** Alta â€” Workers no pueden comunicarse con GCS

---

## Resumen del Plan

| Fase | Tareas | EstimaciÃ³n | Prioridad |
|------|--------|------------|-----------|
| Fase A: Fix CrÃ­ticos (Local) | 3 tareas | 0.5 dÃ­as | ðŸ”´ CrÃ­tico |
| Fase B: Fix Docker/ProducciÃ³n | 3 tareas | 1 dÃ­a | ðŸŸ¡ Alto |
| Fase C: Limpieza de CÃ³digo | 2 tareas | 0.5 dÃ­as | ðŸŸ¢ Medio |
| Fase D: ValidaciÃ³n E2E | 2 tareas | 0.5 dÃ­as | ðŸŸ¢ Medio |
| Fase E: H3 Parquet Export (Post-MVP) | 4 tareas | 3-4 dÃ­as | âšª Futuro |
| **Total** | **14 tareas** | **~6 dÃ­as** | |

---

## Fase A: Fix CrÃ­ticos â€” Entorno Local

> Estas 3 tareas desbloquean la conectividad GCS para desarrollo local.

### T-GCS-01: Activar STORAGE_BACKEND=gcs en .env
- **Prioridad:** ðŸ”´ CrÃ­tico
- **Archivo:** `.env` lÃ­nea 108
- **AcciÃ³n:**
  ```diff
  -STORAGE_BACKEND=local #gcs
  +STORAGE_BACKEND=gcs
  ```
- **Riesgo:** Ninguno. El cÃ³digo ya soporta el backend `gcs`.
- **ValidaciÃ³n:** Ejecutar `python scripts/test_gcs_conn.py`
- **EstimaciÃ³n:** 5 minutos

---

### T-GCS-02: Configurar credenciales GOOGLE_APPLICATION_CREDENTIALS
- **Prioridad:** ðŸ”´ CrÃ­tico
- **Archivo:** `.env` lÃ­nea 112
- **Opciones de configuraciÃ³n (elegir una):**

  **OpciÃ³n A â€” ADC (recomendado para desarrollo):**
  ```bash
  # Ejecutar una sola vez en terminal
  gcloud auth application-default login
  # Esto crea ~/.config/gcloud/application_default_credentials.json
  # El SDK de Google lo detecta automÃ¡ticamente, no necesita variable de entorno
  ```

  **OpciÃ³n B â€” Service Account JSON (recomendado para producciÃ³n):**
  ```diff
  -#GOOGLE_APPLICATION_CREDENTIALS="C:\ruta\absoluta\service-account-gcs.json"
  +GOOGLE_APPLICATION_CREDENTIALS=./secrets/gcs-service-account.json
  ```
  > **Prerequisito:** Descargar el JSON de la Service Account desde GCP Console â†’ IAM â†’ Service Accounts â†’ Keys

- **ValidaciÃ³n:** `python -c "from google.cloud import storage; c = storage.Client(); print('OK')" `
- **EstimaciÃ³n:** 15 minutos

---

### T-GCS-03: Verificar/Crear los 3 buckets en GCS
- **Prioridad:** ðŸ”´ CrÃ­tico
- **AcciÃ³n:** Confirmar que existen en el proyecto `project-fd452487-efa4-4858-8a7`:
  - [ ] `forestguard-images`
  - [ ] `forestguard-reports`
  - [ ] `forestguard-certificates`
- **Comandos de verificaciÃ³n:**
  ```bash
  gsutil ls gs://forestguard-images
  gsutil ls gs://forestguard-reports
  gsutil ls gs://forestguard-certificates
  ```
- **Si no existen, crearlos:**
  ```bash
  gsutil mb -p project-fd452487-efa4-4858-8a7 -l us-central1 gs://forestguard-images
  gsutil mb -p project-fd452487-efa4-4858-8a7 -l us-central1 gs://forestguard-reports
  gsutil mb -p project-fd452487-efa4-4858-8a7 -l us-central1 gs://forestguard-certificates
  ```
- **Permisos IAM necesarios:**
  ```bash
  SA_EMAIL="gcs-sa@project-fd452487-efa4-4858-8a7.iam.gserviceaccount.com"
  gsutil iam ch serviceAccount:$SA_EMAIL:objectAdmin gs://forestguard-images
  gsutil iam ch serviceAccount:$SA_EMAIL:objectCreator gs://forestguard-reports
  gsutil iam ch serviceAccount:$SA_EMAIL:objectCreator gs://forestguard-certificates
  ```
- **EstimaciÃ³n:** 20 minutos

---

## Fase B: Fix Docker / ProducciÃ³n

> Corrige problemas que bloquean el deploy en producciÃ³n con Docker.

### T-GCS-04: Fix user path mismatch en docker-compose.yml
- **Prioridad:** ðŸŸ¡ Alto
- **Archivo:** `docker-compose.yml`
- **Problema:** `Dockerfile.worker` crea usuario `celery`, pero docker-compose monta en `/home/user/`
- **AcciÃ³n:** En los 4 servicios (`api`, `worker-ingestion`, `worker-clustering`, `worker-analysis`):
  ```diff
   environment:
  -  GOOGLE_APPLICATION_CREDENTIALS: /home/user/.config/gcloud/application_default_credentials.json
  +  GOOGLE_APPLICATION_CREDENTIALS: /home/celery/.config/gcloud/application_default_credentials.json
   volumes:
  -  - ~/.config/gcloud:/home/user/.config/gcloud:ro
  +  - ~/.config/gcloud:/home/celery/.config/gcloud:ro
  ```
  > **Nota:** El servicio `api` usa un Dockerfile diferente (`Dockerfile.api`). Verificar quÃ© usuario crea ese Dockerfile. Si tambiÃ©n usa `celery`, aplicar el mismo fix. Si usa otro usuario, ajustar acorde.
- **EstimaciÃ³n:** 30 minutos

---

### T-GCS-05: Agregar STORAGE_BUCKET_* a todos los workers
- **Prioridad:** ðŸŸ¡ Alto
- **Archivo:** `docker-compose.yml`
- **AcciÃ³n:** Agregar las variables de bucket a `worker-ingestion`, `worker-clustering`, y `worker-analysis`:
  ```yaml
  environment:
    # ... existing vars ...
    STORAGE_BACKEND: gcs
    STORAGE_BUCKET_IMAGES: ${STORAGE_BUCKET_IMAGES:-forestguard-images}
    STORAGE_BUCKET_REPORTS: ${STORAGE_BUCKET_REPORTS:-forestguard-reports}
    STORAGE_BUCKET_CERTIFICATES: ${STORAGE_BUCKET_CERTIFICATES:-forestguard-certificates}
  ```
- **Alternativa superior:** Usar YAML anchors (`x-worker-env`) para evitar duplicaciÃ³n (ver propuesta en `gcs_connectivity_diagnostic.md` secciÃ³n 5)
- **EstimaciÃ³n:** 20 minutos

---

### T-GCS-06: Configurar Docker Secrets para producciÃ³n
- **Prioridad:** ðŸŸ¡ Alto
- **Archivos:** `docker-compose.yml`, `secrets/gcs-service-account.json`
- **AcciÃ³n:**
  1. Crear directorio `secrets/` (si no existe)
  2. Descargar Service Account JSON de GCP y guardarlo en `secrets/gcs-service-account.json`
  3. Agregar al `docker-compose.yml`:
     ```yaml
     secrets:
       gcs-sa-key:
         file: ./secrets/gcs-service-account.json
     ```
  4. Actualizar cada worker para montar el secreto:
     ```yaml
     services:
       worker-analysis:
         secrets:
           - gcs-sa-key
         environment:
           GOOGLE_APPLICATION_CREDENTIALS: /run/secrets/gcs-sa-key.json
     ```
  5. Verificar que `secrets/` estÃ¡ en `.gitignore`
- **EstimaciÃ³n:** 30 minutos

---

## Fase C: Limpieza de CÃ³digo

> Elimina deuda tÃ©cnica y previene crashes futuros.

### T-GCS-07: Lazy-init de GCSService singleton
- **Prioridad:** ðŸŸ¢ Medio
- **Archivo:** `app/services/gcs_service.py` lÃ­nea 395
- **Problema:** `gcs_service = GCSService()` se ejecuta al importar el mÃ³dulo â†’ crashea si falta `GCS_PROJECT_ID`
- **AcciÃ³n:**
  ```diff
  -# Singleton global
  -gcs_service = GCSService()
  +# Lazy initialization to avoid crashes on import
  +_gcs_service = None
  +
  +def get_gcs_service() -> GCSService:
  +    """Factory function para obtener instancia singleton de GCSService."""
  +    global _gcs_service
  +    if _gcs_service is None:
  +        _gcs_service = GCSService()
  +    return _gcs_service
  ```
- **Impacto secundario:** Buscar en el codebase usos de `from app.services.gcs_service import gcs_service` y migrar a `get_gcs_service()`
- **EstimaciÃ³n:** 30 minutos

---

### T-GCS-08: Consolidar/eliminar celery_app.py duplicado
- **Prioridad:** ðŸŸ¢ Medio
- **Archivos:** `celery_app.py` (root) y `workers/celery_app.py`
- **Problema:**
  - Root tiene 4 tasks
  - `workers/` tiene 8 tasks (incluye `carousel_task`, `closure_report_task`, `episode_merge_task`, `clustering_task`)
  - Docker usa `workers/celery_app.py` (correcto)
  - `worker_prefetch_multiplier` duplicado en el root
- **AcciÃ³n recomendada:**
  1. Eliminar `celery_app.py` del root
  2. Si algÃºn script local lo referencia, actualizar a usar `workers.celery_app`
  3. Actualizar documentaciÃ³n que referencie al archivo root
- **EstimaciÃ³n:** 20 minutos

---

## Fase D: ValidaciÃ³n End-to-End

### T-GCS-09: Ejecutar test_gcs_conn.py
- **Prioridad:** ðŸŸ¢ Medio
- **Prerequisitos:** T-GCS-01, T-GCS-02, T-GCS-03 completados
- **AcciÃ³n:**
  ```bash
  python scripts/test_gcs_conn.py
  ```
- **Resultado esperado:** 3/3 buckets passed (write, read, delete OK)
- **Si falla:** El script reporta el error exacto (403/404/401) con instrucciones de remediaciÃ³n
- **Artefacto:** `scripts/gcs_diag_report.json` con detalle de cada operaciÃ³n
- **EstimaciÃ³n:** 15 minutos

---

### T-GCS-10: Test de worker E2E con GCS
- **Prioridad:** ðŸŸ¢ Medio
- **Prerequisitos:** T-GCS-09 pasado exitosamente
- **AcciÃ³n:**
  1. Levantar Redis + workers con Docker:
     ```bash
     docker compose up redis worker-analysis -d
     ```
  2. Disparar una tarea de closure report manualmente:
     ```python
     from workers.celery_app import celery_app
     result = celery_app.send_task(
         'workers.tasks.closure_report_task.generate_closure_reports',
         kwargs={'max_fires': 1}
     )
     print(result.get(timeout=120))
     ```
  3. Verificar en GCS Console que se subiÃ³ un archivo a `forestguard-images`
- **EstimaciÃ³n:** 30 minutos

---

## Fase E: ExportaciÃ³n Parquet H3 a GCS (Post-MVP)

> **Contexto:** SegÃºn la arquitectura documentada, los datos H3 procesados por los workers deberÃ­an exportarse como archivos Parquet a GCS para reducir la carga en Supabase PostgreSQL. Actualmente, `h3_recurrence_stats` es una vista materializada en BD. Esta fase implementa el flujo de exportaciÃ³n periÃ³dica.

### T-GCS-11: DiseÃ±ar esquema de exportaciÃ³n H3
- **Prioridad:** âšª Post-MVP
- **Entregable:** Documento de diseÃ±o con:
  - QuÃ© tablas/vistas se exportan: `h3_recurrence_stats`, datos de clustering, series temporales H3
  - Formato Parquet: schema de columnas, particionamiento por fecha/regiÃ³n
  - Frecuencia: diaria (post Celery Beat, ej. 04:00 UTC)
  - Naming convention en GCS: `gs://forestguard-images/h3_exports/YYYY/MM/DD/h3_recurrence.parquet`
  - RetenciÃ³n: 90 dÃ­as de snapshots, luego se archivan a Nearline
- **Dependencias:** T-GCS-01 a T-GCS-10 completados
- **EstimaciÃ³n:** 0.5 dÃ­as

---

### T-GCS-12: Implementar H3ParquetExportService
- **Prioridad:** âšª Post-MVP
- **Archivo nuevo:** `app/services/h3_export_service.py`
- **Responsabilidades:**
  1. Consultar la vista materializada `h3_recurrence_stats` con filtros de fecha
  2. Convertir resultado a DataFrame (pandas/polars)
  3. Exportar a formato Parquet con compresiÃ³n snappy
  4. Subir a GCS via `StorageService` al bucket `forestguard-images` bajo prefix `h3_exports/`
  5. Registrar metadata de exportaciÃ³n en tabla `data_source_metadata`
- **LibrerÃ­as requeridas:**
  ```
  pyarrow>=14.0
  pandas>=2.0  # o polars>=0.20 para mejor performance
  ```
- **Esquema Parquet propuesto:**
  ```
  h3_index:           INT64 (H3 cell index)
  total_fires:        INT32
  fires_last_5_years: INT32
  max_frp_ever:       FLOAT32
  total_hectares:     FLOAT64
  recurrence_class:   STRING (enum: high/medium/low)
  recurrence_score:   FLOAT32
  calculated_at:      TIMESTAMP
  export_date:        DATE (partition key)
  ```
- **PseudocÃ³digo:**
  ```python
  class H3ParquetExportService:
      def __init__(self, db: Session, storage: StorageService):
          self.db = db
          self.storage = storage

      def export_recurrence_stats(self) -> UploadResult:
          # 1. Query h3_recurrence_stats
          rows = self.db.execute(text("SELECT * FROM h3_recurrence_stats")).fetchall()
          
          # 2. Convert to DataFrame
          df = pd.DataFrame(rows, columns=[...])
          
          # 3. Write Parquet to buffer
          buffer = BytesIO()
          df.to_parquet(buffer, engine="pyarrow", compression="snappy")
          
          # 4. Upload to GCS
          today = date.today().isoformat()
          key = f"h3_exports/{today}/h3_recurrence_stats.parquet"
          return self.storage.upload_bytes(
              data=buffer.getvalue(),
              key=key,
              bucket=BUCKETS["images"],
              content_type="application/octet-stream",
              metadata={"export_type": "h3_recurrence", "row_count": str(len(df))}
          )
  ```
- **EstimaciÃ³n:** 1.5 dÃ­as

---

### T-GCS-13: Crear Celery task para exportaciÃ³n H3
- **Prioridad:** âšª Post-MVP
- **Archivo nuevo:** `workers/tasks/h3_export_task.py`
- **AcciÃ³n:**
  1. Crear task `export_h3_parquet` que invoque `H3ParquetExportService`
  2. Registrar en `workers/celery_app.py`:
     ```python
     include=[
         ...,
         'workers.tasks.h3_export_task',
     ]
     ```
  3. Agregar al beat schedule:
     ```python
     'h3-export-daily': {
         'task': 'workers.tasks.h3_export_task.export_h3_parquet',
         'schedule': crontab(hour=4, minute=0),  # 04:00 UTC (tras clustering)
         'options': {'queue': 'analysis'}
     },
     ```
  4. Agregar routing:
     ```python
     'workers.tasks.h3_export_task.export_h3_parquet': {'queue': 'analysis'},
     ```
- **EstimaciÃ³n:** 0.5 dÃ­as

---

### T-GCS-14: Lifecycle policy y monitoreo de exports
- **Prioridad:** âšª Post-MVP
- **Acciones:**
  1. **Lifecycle policy en GCS** (retenciÃ³n de 90 dÃ­as + migraciÃ³n a Nearline):
     ```bash
     gsutil lifecycle set lifecycle.json gs://forestguard-images
     ```
     ```json
     {
       "rule": [
         {
           "action": {"type": "SetStorageClass", "storageClass": "NEARLINE"},
           "condition": {"age": 90, "matchesPrefix": ["h3_exports/"]}
         },
         {
           "action": {"type": "Delete"},
           "condition": {"age": 365, "matchesPrefix": ["h3_exports/"]}
         }
       ]
     }
     ```
  2. **Alertas:** Crear alerta en GCP si no hay nuevos archivos en `h3_exports/` por mÃ¡s de 48 horas
  3. **Dashboard metric:** Agregar contador `h3_parquet_exports_total` al sistema de mÃ©tricas
  4. **Lectura desde frontend:** Endpoint `GET /api/v1/h3/recurrence/download` que genere signed URL al Ãºltimo Parquet
- **EstimaciÃ³n:** 1 dÃ­a

---

## Diagrama de Dependencias del Plan

```
FASE A (CrÃ­tico - 0.5 dÃ­as)
â”œâ”€â”€ T-GCS-01: STORAGE_BACKEND=gcs
â”œâ”€â”€ T-GCS-02: Configurar credenciales
â””â”€â”€ T-GCS-03: Verificar/crear buckets
         â”‚
         â–¼
FASE B (Alto - 1 dÃ­a)                    FASE C (Medio - 0.5 dÃ­as)
â”œâ”€â”€ T-GCS-04: Fix Docker user path       â”œâ”€â”€ T-GCS-07: Lazy-init GCSService
â”œâ”€â”€ T-GCS-05: Agregar BUCKET vars        â””â”€â”€ T-GCS-08: Consolidar celery_app
â””â”€â”€ T-GCS-06: Docker Secrets                      â”‚
         â”‚                                         â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
                  FASE D (Medio - 0.5 dÃ­as)
                  â”œâ”€â”€ T-GCS-09: test_gcs_conn.py
                  â””â”€â”€ T-GCS-10: Test worker E2E
                           â”‚
                           â–¼
                  FASE E (Post-MVP - 3-4 dÃ­as)
                  â”œâ”€â”€ T-GCS-11: DiseÃ±o esquema H3 Parquet
                  â”œâ”€â”€ T-GCS-12: H3ParquetExportService
                  â”œâ”€â”€ T-GCS-13: Celery task h3_export
                  â””â”€â”€ T-GCS-14: Lifecycle + monitoreo
```

---

*Documento generado: 2026-02-09*  
*Referencia: `gcs_connectivity_diagnostic.md`*  
*Script de validaciÃ³n: `scripts/test_gcs_conn.py`*
