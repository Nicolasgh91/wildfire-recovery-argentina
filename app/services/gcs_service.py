"""
Google Cloud Storage Service para ForestGuard
Maneja subida y descarga de im√°genes satelitales usando Application Default Credentials

La raz√≥n por la que usamos ADC en lugar de Service Account JSON es la seguridad.
Con Service Account JSON, tienes una clave privada que puede ser expuesta en logs,
variables de entorno, o backups accidentales. Con ADC, Google Cloud detecta
autom√°ticamente d√≥nde est√°s corriendo (local, Docker, Cloud Run) y busca
credenciales v√°lidas en el orden correcto sin que el desarrollador maneje claves.

En desarrollo: Lee de ~/.config/gcloud/application_default_credentials.json
En Docker: Lee del volumen montado que apunta a tu ~/.config/gcloud/
En Cloud Run: Autom√°tico via metadata service, sin configuraci√≥n manual

Esta arquitectura es mucho m√°s segura y sigue las mejores pr√°cticas de Google Cloud.
"""

import logging
import os
from datetime import timedelta
from io import BytesIO
from pathlib import Path
from typing import BinaryIO, Optional

from google.auth.exceptions import DefaultCredentialsError
from google.cloud import storage

logger = logging.getLogger(__name__)


class GCSService:
    """
    Servicio para interactuar con Google Cloud Storage.

    Esta clase proporciona m√©todos simples para las operaciones m√°s comunes:
    - Subir archivos
    - Descargar archivos
    - Generar URLs presignadas (acceso temporal sin credenciales GCS)
    - Borrar archivos

    El patr√≥n de dise√±o aqu√≠ es Singleton: se crea una sola instancia del servicio
    que se reutiliza en toda la aplicaci√≥n. Esto es importante porque el cliente
    de GCS mantiene una conexi√≥n que puede ser costosa de recrear.
    """

    _instance = None  # Para patr√≥n Singleton

    def __new__(cls, *args, **kwargs):
        """
        Patr√≥n Singleton: asegura que solo existe una instancia del servicio.
        Cuando alguien llama a GCSService(), siempre obtiene la misma instancia.
        """
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self, project_id: Optional[str] = None):
        """
        Inicializa el servicio GCS.

        Args:
            project_id: ID del proyecto GCP. Si no se proporciona, se intenta
                       obtener del ambiente. En Cloud Run, se detecta autom√°ticamente.

        Raises:
            DefaultCredentialsError: Si no se pueden encontrar credenciales v√°lidas.
            ValueError: Si no se puede determinar el project_id.
        """
        # Solo inicializar una vez (patr√≥n Singleton)
        if self._initialized:
            return

        # Obtener project ID
        if not project_id:
            project_id = os.getenv("GCS_PROJECT_ID")

        if not project_id:
            raise ValueError(
                "GCS_PROJECT_ID no est√° configurado. "
                "Agrega a .env: GCS_PROJECT_ID=tu-gcp-project-id"
            )

        self.project_id = project_id

        # Crear cliente de GCS
        # IMPORTANTE: No pasamos credenciales expl√≠citamente.
        # El cliente de Google Cloud busca autom√°ticamente en:
        # 1. Variable de entorno GOOGLE_APPLICATION_CREDENTIALS (archivo JSON)
        # 2. ~/.config/gcloud/application_default_credentials.json (local)
        # 3. Metadata service (Cloud Run, Compute Engine, Kubernetes)
        # 4. Credenciales del usuario logueado en gcloud CLI
        try:
            self.client = storage.Client(project=project_id)
            logger.info(f"‚úÖ GCS client inicializado para proyecto: {project_id}")
        except DefaultCredentialsError as e:
            logger.error(
                "‚ùå No se encontraron credenciales de GCP v√°lidas. "
                "En desarrollo, ejecuta: gcloud auth application-default login"
            )
            raise

        self._initialized = True

    def upload_image(
        self,
        local_file_path: str,
        bucket_name: str,
        destination_blob_name: str,
        content_type: str = "image/tiff",
    ) -> Optional[str]:
        """
        Sube un archivo local a Google Cloud Storage.

        Args:
            local_file_path: Ruta del archivo en tu m√°quina/contenedor
            bucket_name: Nombre del bucket GCS (ej: "forestguard-images")
            destination_blob_name: Ruta dentro del bucket (ej: "hd/incendio_123.tif")
            content_type: MIME type del archivo (ej: "image/tiff", "image/jpeg")

        Returns:
            URL p√∫blica del archivo, o None si hay error

        Ejemplo de uso en un worker Celery:

            @celery_app.task
            def download_and_upload_satellite_image(fire_id):
                # Descargar imagen desde API
                image_data = download_from_nasa_api(fire_id)

                # Guardar localmente temporalmente
                temp_path = f"/tmp/{fire_id}.tif"
                with open(temp_path, 'wb') as f:
                    f.write(image_data)

                # Subir a GCS
                gcs = GCSService()
                public_url = gcs.upload_image(
                    local_file_path=temp_path,
                    bucket_name="forestguard-images",
                    destination_blob_name=f"hd/{fire_id}.tif",
                    content_type="image/tiff"
                )

                # Guardar URL en BD para acceso posterior
                db.execute(
                    "UPDATE fire_detections SET image_url = %s WHERE id = %s",
                    (public_url, fire_id)
                )

                # Limpiar archivo temporal
                os.remove(temp_path)

                return public_url
        """
        try:
            bucket = self.client.bucket(bucket_name)
            blob = bucket.blob(destination_blob_name)

            # Configurar tipo de contenido (permite al navegador mostrar imagen directamente)
            blob.content_type = content_type

            # Subir el archivo
            logger.info(f"‚¨ÜÔ∏è  Subiendo {destination_blob_name} a {bucket_name}...")
            blob.upload_from_filename(local_file_path)

            # Hacer la imagen p√∫blica para acceso sin credenciales
            # En producci√≥n, podr√≠as usar URLs presignadas en lugar de esto
            # (m√°s seguro, expira autom√°ticamente despu√©s de tiempo)
            blob.make_public()

            public_url = blob.public_url
            logger.info(f"‚úÖ Archivo subido: {public_url}")

            return public_url

        except Exception as e:
            logger.error(f"‚ùå Error subiendo a GCS: {e}")
            return None

    def upload_from_bytes(
        self,
        file_bytes: bytes,
        bucket_name: str,
        destination_blob_name: str,
        content_type: str = "image/tiff",
    ) -> Optional[str]:
        """
        Sube un archivo desde bytes (√∫til para datos en memoria).

        Args:
            file_bytes: Contenido del archivo en bytes
            bucket_name: Nombre del bucket GCS
            destination_blob_name: Ruta dentro del bucket
            content_type: MIME type

        Returns:
            URL p√∫blica del archivo

        Ejemplo en un worker:

            @celery_app.task
            def process_fire_image(fire_id, image_bytes):
                gcs = GCSService()
                url = gcs.upload_from_bytes(
                    file_bytes=image_bytes,
                    bucket_name="forestguard-images",
                    destination_blob_name=f"hd/{fire_id}.tif"
                )
                return url
        """
        try:
            bucket = self.client.bucket(bucket_name)
            blob = bucket.blob(destination_blob_name)
            blob.content_type = content_type

            logger.info(
                f"‚¨ÜÔ∏è  Subiendo {destination_blob_name} ({len(file_bytes)} bytes)..."
            )
            blob.upload_from_string(file_bytes)
            blob.make_public()

            public_url = blob.public_url
            logger.info(f"‚úÖ Archivo subido: {public_url}")

            return public_url

        except Exception as e:
            logger.error(f"‚ùå Error subiendo a GCS: {e}")
            return None

    def download_image(self, bucket_name: str, blob_name: str) -> Optional[bytes]:
        """
        Descarga un archivo de GCS como bytes.

        Args:
            bucket_name: Nombre del bucket
            blob_name: Ruta del archivo dentro del bucket

        Returns:
            Contenido del archivo en bytes, o None si error

        √ötil cuando necesitas procesar una imagen ya almacenada:

            gcs = GCSService()
            image_bytes = gcs.download_image(
                bucket_name="forestguard-images",
                blob_name="hd/incendio_123.tif"
            )
            # Procesar image_bytes...
        """
        try:
            bucket = self.client.bucket(bucket_name)
            blob = bucket.blob(blob_name)

            logger.info(f"‚¨áÔ∏è  Descargando {blob_name}...")
            data = blob.download_as_bytes()
            logger.info(f"‚úÖ Descargado: {len(data)} bytes")

            return data

        except Exception as e:
            logger.error(f"‚ùå Error descargando de GCS: {e}")
            return None

    def get_signed_url(
        self, bucket_name: str, blob_name: str, expiration_hours: int = 24
    ) -> Optional[str]:
        """
        Genera una URL presignada (temporal) para acceso sin credenciales GCS.

        Una URL presignada es m√°s segura que hacer un blob p√∫blico porque:
        - Solo funciona durante el per√≠odo especificado (por defecto 24 horas)
        - Incluye firma criptogr√°fica que valida la solicitud
        - No requiere que el usuario tenga credenciales de GCS

        Args:
            bucket_name: Nombre del bucket
            blob_name: Ruta del archivo
            expiration_hours: Cu√°ntas horas ser√° v√°lida la URL (m√°ximo 7 d√≠as)

        Returns:
            URL presignada que puede compartirse con usuarios

        Ejemplo en un endpoint FastAPI:

            @app.get("/reports/{fire_id}/download")
            def download_report(fire_id: str, db: Session = Depends(get_db)):
                # Obtener ubicaci√≥n del reporte de BD
                report = db.query(DestructionReport).filter(
                    DestructionReport.fire_id == fire_id
                ).first()

                if not report:
                    raise HTTPException(404, "Reporte no encontrado")

                # Generar URL presignada para descargar
                gcs = GCSService()
                download_url = gcs.get_signed_url(
                    bucket_name="forestguard-reports",
                    blob_name=report.gcs_path,
                    expiration_hours=24
                )

                return {"download_url": download_url, "expires_in_hours": 24}
        """
        try:
            bucket = self.client.bucket(bucket_name)
            blob = bucket.blob(blob_name)

            # Generar URL firmada que expira en N horas
            signed_url = blob.generate_signed_url(
                version="v4",  # Versi√≥n m√°s nueva de Google Cloud Storage
                expiration=timedelta(hours=expiration_hours),  # Cuando expira
            )

            logger.info(
                f"üîó URL presignada generada para {blob_name} (v√°lida {expiration_hours}h)"
            )
            return signed_url

        except Exception as e:
            logger.error(f"‚ùå Error generando URL presignada: {e}")
            return None

    def delete_image(self, bucket_name: str, blob_name: str) -> bool:
        """
        Borra un archivo de GCS.

        Args:
            bucket_name: Nombre del bucket
            blob_name: Ruta del archivo a borrar

        Returns:
            True si se borr√≥ exitosamente, False si hay error

        √ötil para limpiar archivos temporales o cuando se borra un evento:

            gcs = GCSService()
            if gcs.delete_image("forestguard-images", "hd/temp_file.tif"):
                logger.info("Archivo borrado")
            else:
                logger.error("Fallo al borrar")
        """
        try:
            bucket = self.client.bucket(bucket_name)
            blob = bucket.blob(blob_name)

            logger.info(f"üóëÔ∏è  Borrando {blob_name}...")
            blob.delete()
            logger.info(f"‚úÖ Archivo borrado")

            return True

        except Exception as e:
            logger.error(f"‚ùå Error borrando de GCS: {e}")
            return False

    def list_blobs(self, bucket_name: str, prefix: str = "") -> list:
        """
        Lista todos los archivos en un bucket (opcionalmente filtrado por prefijo).

        Args:
            bucket_name: Nombre del bucket
            prefix: Filtrar por prefijo (ej: "hd/" para solo archivos HD)

        Returns:
            Lista de nombres de blobs (archivos)

        √ötil para auditor√≠a o limpieza:

            gcs = GCSService()
            all_hd_images = gcs.list_blobs(
                bucket_name="forestguard-images",
                prefix="hd/"
            )
            print(f"Total im√°genes HD: {len(all_hd_images)}")
        """
        try:
            bucket = self.client.bucket(bucket_name)
            blobs = bucket.list_blobs(prefix=prefix)

            # Retornar nombres de los blobs
            return [blob.name for blob in blobs]

        except Exception as e:
            logger.error(f"‚ùå Error listando blobs: {e}")
            return []


# Singleton global para usar en toda la aplicaci√≥n
# En lugar de crear new GCSService() cada vez, importas esto:
#   from gcs_service import gcs_service
#   gcs_service.upload_image(...)
gcs_service = GCSService()
